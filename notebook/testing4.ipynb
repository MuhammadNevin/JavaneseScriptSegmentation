{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (1000, 15, 59)\n",
      "X_ngram shape: (1000, 1)\n",
      "Y_data shape: (1000, 2)\n",
      "X_ngram: [0.71472595]\n",
      "Y_data: [0.09323565 0.20106089]\n",
      "Total params:  8996\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 15, 59)]     0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_6 (GRU)                    (None, 32)           8928        ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1)            0           ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 33)           0           ['gru_6[0][0]',                  \n",
      "                                                                  'flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            68          ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,996\n",
      "Trainable params: 8,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 09:11:02.550281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-06-20 09:11:02.551943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-06-20 09:11:02.553267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-06-20 09:11:02.633922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-20 09:11:02.788730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-06-20 09:11:02.790053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-06-20 09:11:02.791000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-06-20 09:11:03.236309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-06-20 09:11:03.237816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-06-20 09:11:03.239381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 13ms/step - loss: 0.7084 - accuracy: 0.5094\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.7002 - accuracy: 0.5063\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6996 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6980 - accuracy: 0.5188\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5198\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5052\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6947 - accuracy: 0.5323\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.5354\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.5333\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa36bad2640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Concatenate, Dense, Flatten\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_data, X_ngram, Y_data, batch_size=64):\n",
    "        self.X_data = X_data\n",
    "        self.X_ngram = X_ngram\n",
    "        self.Y_data = Y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(X_data))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X1_batch = self.X_data[indices]\n",
    "        X2_batch = self.X_ngram[indices]\n",
    "        y_batch = self.Y_data[indices]\n",
    "        return [X1_batch, X2_batch], y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# Example shapes for the data, replace these with your actual data loading\n",
    "X_data = np.random.rand(1000, 15, 59)  # Example data for X1\n",
    "X_ngram = np.random.rand(1000, 1).astype(float)  # Example data for X2 as floats\n",
    "Y_data = np.random.rand(1000, 2)  # Example data for y\n",
    "\n",
    "print('X_data shape:', X_data.shape)\n",
    "print('X_ngram shape:', X_ngram.shape)\n",
    "print('Y_data shape:', Y_data.shape)\n",
    "\n",
    "# print example\n",
    "# print('X_data:', X_data[0])\n",
    "print('X_ngram:', X_ngram[0])\n",
    "print('Y_data:', Y_data[0])\n",
    "\n",
    "\n",
    "# Define the model using the provided function\n",
    "def define_model(input1_shape, input2_shape):\n",
    "    input1 = Input(shape=input1_shape)\n",
    "    input2 = Input(shape=input2_shape)\n",
    "    gru_output = GRU(32, return_sequences=False)(input1)\n",
    "    flat2 = Flatten()(input2)\n",
    "\n",
    "    concatenated = Concatenate()([gru_output, flat2])\n",
    "    output = Dense(2, activation='softmax')(concatenated)\n",
    "    model = Model(inputs=[input1, input2], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])  # compile\n",
    "\n",
    "    print('Total params: ', model.count_params())\n",
    "    return model\n",
    "\n",
    "# Define input shapes\n",
    "input1_shape = (15, 59)  # Shape of X_data (X1)\n",
    "input2_shape = (1,)  # Shape of X_ngram (X2)\n",
    "\n",
    "# Create the model\n",
    "model = define_model(input1_shape, input2_shape)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Create the data generator\n",
    "batch_size = 64\n",
    "data_generator = DataGenerator(X_data, X_ngram, Y_data, batch_size=batch_size)\n",
    "\n",
    "# Fit the model using the data generator\n",
    "model.fit(data_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 10:27:00.544924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 10:27:01.161124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 60 into shape (3,4,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m X_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m X_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 50\u001b[0m X_data_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mX_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Define the dataset generator class\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataGenerator\u001b[39;00m(Sequence):\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 60 into shape (3,4,1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Concatenate, Dense, Flatten\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Example data\n",
    "X_data = np.array([[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "],\n",
    "[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "],\n",
    "[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "]])\n",
    "\n",
    "X_ngram = np.array([[\n",
    "    0.0, 0.0, 1.0\n",
    "],\n",
    "[\n",
    "    0.0, 0.0, 1.0\n",
    "],\n",
    "[\n",
    "    0.0, 0.0, 1.0\n",
    "]])\n",
    "\n",
    "Y_data = np.array([[\n",
    "    0., 1.\n",
    "],\n",
    "[\n",
    "    0., 1.\n",
    "],\n",
    "[\n",
    "    0., 1.\n",
    "]])\n",
    "\n",
    "# Reshape X_data to have an additional dimension for timesteps\n",
    "num_samples = X_data.shape[0]\n",
    "sequence_length = X_data.shape[1]\n",
    "X_data_reshaped = X_data.reshape(num_samples, sequence_length, 1)\n",
    "\n",
    "# Define the dataset generator class\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_data, X_ngram, Y_data, batch_size=64):\n",
    "        self.X_data = X_data\n",
    "        self.X_ngram = X_ngram\n",
    "        self.Y_data = Y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(X_data))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X1_batch = self.X_data[indices]\n",
    "        X2_batch = np.array([self.X_ngram] * len(indices))  # Repeat X_ngram for each batch\n",
    "        y_batch = self.Y_data[indices]\n",
    "        return [X1_batch, X2_batch], y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "# Define input shapes\n",
    "input1_shape = X_data_reshaped.shape[1:]  # Shape of X_data (X1)\n",
    "input2_shape = X_ngram.shape[0]  # Shape of X_ngram (X2)\n",
    "\n",
    "# Define the model using the provided function\n",
    "def define_model(input1_shape, input2_shape):\n",
    "    input1 = Input(shape=input1_shape)\n",
    "    input2 = Input(shape=(input2_shape,))\n",
    "    gru_output = GRU(32, return_sequences=False)(input1)  # Adjusted to expect 3D input\n",
    "    flat2 = Flatten()(input2)\n",
    "\n",
    "    concatenated = Concatenate()([gru_output, flat2])\n",
    "    output = Dense(2, activation='softmax')(concatenated)\n",
    "    model = Model(inputs=[input1, input2], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    print('Total params: ', model.count_params())\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = define_model(input1_shape, input2_shape)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Create the data generator\n",
    "batch_size = 4  # Choose a batch size that fits your memory constraints\n",
    "data_generator = DataGenerator(X_data_reshaped, X_ngram, Y_data, batch_size=batch_size)\n",
    "\n",
    "# Fit the model using the data generator\n",
    "model.fit(data_generator, epochs=5, steps_per_epoch=len(data_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data :  [[0.  0.  0.  0.  0.1]\n",
      " [0.  0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0.  0. ]\n",
      " [0.  0.1 0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_data = np.array([[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "],\n",
    "[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "],\n",
    "[\n",
    "    [0., 0., 0., 0., 0.1],\n",
    "    [0., 0., 0., 0.1, 0.],\n",
    "    [0., 0., 0.1, 0., 0.],\n",
    "    [0., 0.1, 0., 0., 0.],\n",
    "]])\n",
    "\n",
    "X_ngram = np.array([[\n",
    "    0.0, 0.0, 1.0\n",
    "],\n",
    "[\n",
    "    0.0, 0.0, 1.0\n",
    "],\n",
    "[\n",
    "    0.0, 0.0, 1.0\n",
    "]])\n",
    "\n",
    "Y_data = np.array([[\n",
    "    0., 1.\n",
    "],\n",
    "[\n",
    "    0., 1.\n",
    "],\n",
    "[\n",
    "    0., 1.\n",
    "]])\n",
    "\n",
    "print('X_data : ', X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
